{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hxIDJYP3AqN",
        "outputId": "eff89357-c4e8-4306-ccb7-dec371c94087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/elli\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/MyDrive/elli\"\n",
        "os.chdir(path)\n",
        "\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function of the Code\n",
        "\n",
        "1. **Install dependency**\n",
        "   - Installs the `torch-geometric` library (quiet mode).\n",
        "\n",
        "2. **Import required libraries**\n",
        "   - `torch` and `torch.nn.functional`: Core PyTorch operations.\n",
        "   - `accuracy_score` from `sklearn.metrics`: Model evaluation.\n",
        "   - `EllipticBitcoinDataset` from `torch_geometric.datasets`: Loads the Elliptic Bitcoin transaction dataset.\n",
        "   - `SAGEConv` and `DeepGraphInfomax` from `torch_geometric.nn`: GNN layers and self-supervised learning method.\n",
        "\n",
        "3. **Set device**\n",
        "   - Uses GPU (`'cuda'`) if available; otherwise defaults to CPU.\n",
        "\n",
        "4. **Load dataset**\n",
        "   - Downloads/loads the Elliptic Bitcoin dataset to `./elliptic`.\n",
        "   - Selects the first (and only) graph object and moves it to the chosen device.\n"
      ],
      "metadata": {
        "id": "tdtnT62UNMdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install torch-geometric -q\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch_geometric.datasets import EllipticBitcoinDataset\n",
        "from torch_geometric.nn import SAGEConv, DeepGraphInfomax\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "dataset = EllipticBitcoinDataset(root='./elliptic')\n",
        "data = dataset[0].to(device)\n"
      ],
      "metadata": {
        "id": "bktlhkuPtbqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eef77f98-0a68-416a-8a44-fef7af18d0a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://data.pyg.org/datasets/elliptic/elliptic_txs_features.csv.zip\n",
            "Downloading https://data.pyg.org/datasets/elliptic/elliptic_txs_edgelist.csv.zip\n",
            "Downloading https://data.pyg.org/datasets/elliptic/elliptic_txs_classes.csv.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function of the Code\n",
        "\n",
        "1. **Print data object structure**\n",
        "   - Displays the overall `data` object from the Elliptic Bitcoin dataset, which contains graph structure, features, and labels.\n",
        "\n",
        "2. **Print graph statistics**\n",
        "   - Number of nodes (`data.num_nodes`)\n",
        "   - Number of edges (`data.num_edges`)\n",
        "   - Feature dimension (`data.num_node_features`)\n",
        "\n",
        "3. **Print label distribution**\n",
        "   - Uses `torch.unique()` to get all unique labels and their counts.\n",
        "   - Iterates through labels to print the number of nodes per class.\n",
        "\n",
        "4. **Print train/test split information**\n",
        "   - Counts and prints the number of nodes in the training set (`data.train_mask`).\n",
        "   - Counts and prints the number of nodes in the testing set (`data.test_mask`).\n"
      ],
      "metadata": {
        "id": "k6l6zvbANOZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data object structure:\", data)\n",
        "print(f\"Number of nodes: {data.num_nodes}, Number of edges: {data.num_edges}, Feature dimension: {data.num_node_features}\")\n",
        "\n",
        "unique, counts = torch.unique(data.y, return_counts=True)\n",
        "print(\"Label distribution:\")\n",
        "for label, count in zip(unique.tolist(), counts.tolist()):\n",
        "    print(f\"  Label {label}: {count} nodes\")\n",
        "\n",
        "print(f\"Number of training nodes: {data.train_mask.sum().item()}, Number of testing nodes: {data.test_mask.sum().item()}\")\n"
      ],
      "metadata": {
        "id": "VKPPjQAIw0_i",
        "outputId": "2f3d1e7a-4fb0-4dfa-c1a3-acba91b402b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data object structure: Data(x=[203769, 165], edge_index=[2, 234355], y=[203769], train_mask=[203769], test_mask=[203769])\n",
            "Number of nodes: 203769, Number of edges: 234355, Feature dimension: 165\n",
            "Label distribution:\n",
            "  Label 0: 42019 nodes\n",
            "  Label 1: 4545 nodes\n",
            "  Label 2: 157205 nodes\n",
            "Number of training nodes: 29894, Number of testing nodes: 16670\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function of the Code\n",
        "\n",
        "1. **Define `GraphSAGE` model**\n",
        "   - Two-layer GraphSAGE architecture:\n",
        "     - `SAGEConv(in_channels → hidden_channels)`\n",
        "     - `ReLU` activation\n",
        "     - `SAGEConv(hidden_channels → out_channels)`\n",
        "\n",
        "2. **Initialize model and optimizer**\n",
        "   - Creates `model1` with:\n",
        "     - Input features = `data.num_features`\n",
        "     - Hidden dimension = 64\n",
        "     - Output dimension = 2 (binary classification)\n",
        "   - Uses Adam optimizer with learning rate 0.01.\n",
        "\n",
        "3. **`train(model, optimizer)`**\n",
        "   - Sets model to training mode.\n",
        "   - Performs forward pass on all nodes.\n",
        "   - Computes cross-entropy loss on training nodes (`data.train_mask`).\n",
        "   - Backpropagates and updates parameters.\n",
        "   - Returns the loss value.\n",
        "\n",
        "4. **`evaluate(model)`**\n",
        "   - Sets model to evaluation mode.\n",
        "   - Performs forward pass to get predictions.\n",
        "   - Selects predicted class labels (`argmax`).\n",
        "   - Computes accuracy on test nodes (`data.test_mask`).\n",
        "\n",
        "5. **Train loop**\n",
        "   - Runs for 50 epochs.\n",
        "   - Every 10 epochs:\n",
        "     - Evaluates the model on the test set.\n",
        "     - Prints epoch, loss, and test accuracy.\n"
      ],
      "metadata": {
        "id": "rgMyOiG3Nv0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define GraphSAGE model\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        return self.conv2(x, edge_index)\n",
        "\n",
        "model1 = GraphSAGE(data.num_features, 64, 2).to(device)\n",
        "opt1 = torch.optim.Adam(model1.parameters(), lr=0.01)\n",
        "\n",
        "# Training function\n",
        "def train(model, optimizer):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# Evaluation function\n",
        "@torch.no_grad()\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    pred = out.argmax(dim=1)\n",
        "    acc = accuracy_score(data.y[data.test_mask].cpu(), pred[data.test_mask].cpu())\n",
        "    return acc\n",
        "\n",
        "# Train GraphSAGE\n",
        "for epoch in range(1, 51):\n",
        "    loss = train(model1, opt1)\n",
        "    if epoch % 10 == 0:\n",
        "        acc1 = evaluate(model1)\n",
        "        print(f'[GraphSAGE] Epoch {epoch} | Loss: {loss:.4f} | Test Acc: {acc1:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMmzZCxdvS1B",
        "outputId": "e861b3aa-e7eb-42a6-f106-022a1036f4c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE] Epoch 10 | Loss: 0.1742 | Test Acc: 0.9196\n",
            "[GraphSAGE] Epoch 20 | Loss: 0.1184 | Test Acc: 0.9259\n",
            "[GraphSAGE] Epoch 30 | Loss: 0.0942 | Test Acc: 0.9314\n",
            "[GraphSAGE] Epoch 40 | Loss: 0.0785 | Test Acc: 0.9365\n",
            "[GraphSAGE] Epoch 50 | Loss: 0.0669 | Test Acc: 0.9376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function of the Code\n",
        "\n",
        "1. **Define `GraphSAGE` model**\n",
        "   - A two-layer GraphSAGE architecture:\n",
        "     - First layer: `SAGEConv(in_channels → hidden_channels)` followed by ReLU activation.\n",
        "     - Second layer: `SAGEConv(hidden_channels → out_channels)` to produce class logits.\n",
        "\n",
        "2. **Initialize model and optimizer**\n",
        "   - Creates `model1` with:\n",
        "     - Input features = `data.num_features`\n",
        "     - Hidden dimension = 64\n",
        "     - Output dimension = 2 (binary classification)\n",
        "   - Uses Adam optimizer with learning rate 0.01.\n",
        "\n",
        "3. **`train(model, optimizer)`**\n",
        "   - Sets the model to training mode.\n",
        "   - Computes forward pass for all nodes.\n",
        "   - Calculates cross-entropy loss on **training nodes** (`data.train_mask`).\n",
        "   - Performs backpropagation and updates model parameters.\n",
        "   - Returns the loss value.\n",
        "\n",
        "4. **`evaluate(model)`**\n",
        "   - Sets the model to evaluation mode.\n",
        "   - Runs forward pass to get predicted logits.\n",
        "   - Selects class predictions with `argmax`.\n",
        "   - Calculates accuracy on **test nodes** (`data.test_mask`).\n",
        "\n",
        "5. **Training loop**\n",
        "   - Trains for 50 epochs.\n",
        "   - Every 10 epochs:\n",
        "     - Evaluates the model on the test set.\n",
        "     - Prints epoch number, training loss, and test accuracy.\n"
      ],
      "metadata": {
        "id": "kMXe4WW0N7PX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define GraphSAGE model\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        return self.conv2(x, edge_index)\n",
        "\n",
        "model1 = GraphSAGE(data.num_features, 64, 2).to(device)\n",
        "opt1 = torch.optim.Adam(model1.parameters(), lr=0.01)\n",
        "\n",
        "# Training function\n",
        "def train(model, optimizer):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# Evaluation function\n",
        "@torch.no_grad()\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    pred = out.argmax(dim=1)\n",
        "    acc = accuracy_score(data.y[data.test_mask].cpu(), pred[data.test_mask].cpu())\n",
        "    return acc\n",
        "\n",
        "# Train GraphSAGE\n",
        "for epoch in range(1, 51):\n",
        "    loss = train(model1, opt1)\n",
        "    if epoch % 10 == 0:\n",
        "        acc1 = evaluate(model1)\n",
        "        print(f'[GraphSAGE] Epoch {epoch} | Loss: {loss:.4f} | Test Acc: {acc1:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rPXnDNjvXDq",
        "outputId": "9e8a6a9d-5159-4c8c-e295-1ca78061d65e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE] Epoch 10 | Loss: 0.1789 | Test Acc: 0.9379\n",
            "[GraphSAGE] Epoch 20 | Loss: 0.1239 | Test Acc: 0.9304\n",
            "[GraphSAGE] Epoch 30 | Loss: 0.0958 | Test Acc: 0.9374\n",
            "[GraphSAGE] Epoch 40 | Loss: 0.0790 | Test Acc: 0.9418\n",
            "[GraphSAGE] Epoch 50 | Loss: 0.0669 | Test Acc: 0.9461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function of the Code\n",
        "\n",
        "1. **Define DGI Encoder (`Encoder` class)**\n",
        "   - Uses a single `SAGEConv` layer to produce node embeddings.\n",
        "   - `forward()`: Generates embeddings from input features and graph structure.\n",
        "   - `summary()`: Computes a global summary vector using the mean of embeddings with sigmoid activation.\n",
        "\n",
        "2. **Initialize Deep Graph Infomax (DGI)**\n",
        "   - `hidden_channels=64`: Embedding size.\n",
        "   - `encoder`: The custom SAGE-based encoder.\n",
        "   - `summary`: The encoder’s summary function.\n",
        "   - `corruption`: Node feature corruption by randomly shuffling rows (negative samples).\n",
        "   - Moves DGI model to the selected device (CPU/GPU).\n",
        "\n",
        "3. **Train DGI**\n",
        "   - Runs for 100 epochs.\n",
        "   - In each epoch:\n",
        "     - Gets positive (`pos_z`) and negative (`neg_z`) embeddings and summary vector.\n",
        "     - Computes DGI loss to maximize mutual information between graph patches and summary.\n",
        "     - Updates parameters with Adam optimizer.\n",
        "   - Prints loss every 20 epochs.\n",
        "\n",
        "4. **Generate embeddings**\n",
        "   - After training, uses the encoder to compute node embeddings `z` without gradient tracking.\n",
        "\n",
        "5. **Define simple classifier (`Classifier` class)**\n",
        "   - A single linear layer mapping embeddings to 2 output classes.\n",
        "\n",
        "6. **Train classifier on embeddings**\n",
        "   - Runs for 50 epochs.\n",
        "   - Uses cross-entropy loss on training nodes.\n",
        "   - Every 10 epochs:\n",
        "     - Evaluates on test nodes and prints loss + accuracy.\n"
      ],
      "metadata": {
        "id": "yAxE9H6nN-O8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define DGI encoder (SAGE)\n",
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.conv = SAGEConv(in_channels, hidden_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        return self.conv(x, edge_index)\n",
        "\n",
        "    def summary(self, z, *args, **kwargs):\n",
        "        return torch.sigmoid(z.mean(dim=0))\n",
        "\n",
        "encoder = Encoder(data.num_features, 64).to(device)\n",
        "dgi = DeepGraphInfomax(\n",
        "    hidden_channels=64,\n",
        "    encoder=encoder,\n",
        "    summary=encoder.summary,\n",
        "    corruption=lambda x, edge_index: (x[torch.randperm(x.size(0))], edge_index),\n",
        ").to(device)\n",
        "\n",
        "opt2 = torch.optim.Adam(dgi.parameters(), lr=0.001)\n",
        "\n",
        "# Train DGI\n",
        "for epoch in range(1, 101):\n",
        "    dgi.train()\n",
        "    opt2.zero_grad()\n",
        "    pos_z, neg_z, summary = dgi(data.x, data.edge_index)\n",
        "    loss = dgi.loss(pos_z, neg_z, summary)\n",
        "    loss.backward()\n",
        "    opt2.step()\n",
        "    if epoch % 20 == 0:\n",
        "        print(f'[DGI] Epoch {epoch} | Loss: {loss.item():.4f}')\n",
        "\n",
        "# Use the trained encoder to get z\n",
        "with torch.no_grad():\n",
        "    z = encoder(data.x, data.edge_index).detach()\n",
        "\n",
        "# Define a simple classifier using z\n",
        "class Classifier(torch.nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.lin = torch.nn.Linear(in_dim, out_dim)\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.lin(z)\n",
        "\n",
        "clf = Classifier(64, 2).to(device)\n",
        "opt3 = torch.optim.Adam(clf.parameters(), lr=0.01)\n",
        "\n",
        "# Train classifier\n",
        "for epoch in range(1, 51):\n",
        "    clf.train()\n",
        "    opt3.zero_grad()\n",
        "    out = clf(z)\n",
        "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    opt3.step()\n",
        "    if epoch % 10 == 0:\n",
        "        clf.eval()\n",
        "        pred = out.argmax(dim=1)\n",
        "        acc2 = accuracy_score(data.y[data.test_mask].cpu(), pred[data.test_mask].cpu())\n",
        "        print(f'[DGI+Classifier] Epoch {epoch} | Loss: {loss.item():.4f} | Test Acc: {acc2:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqz110OGvZQI",
        "outputId": "9e6e1335-fad3-42bd-9460-7142921edfac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DGI] Epoch 20 | Loss: 1.3332\n",
            "[DGI] Epoch 40 | Loss: 1.3168\n",
            "[DGI] Epoch 60 | Loss: 1.3127\n",
            "[DGI] Epoch 80 | Loss: 1.3079\n",
            "[DGI] Epoch 100 | Loss: 1.3077\n",
            "[DGI+Classifier] Epoch 10 | Loss: 0.3885 | Test Acc: 0.4195\n",
            "[DGI+Classifier] Epoch 20 | Loss: 0.3062 | Test Acc: 0.5254\n",
            "[DGI+Classifier] Epoch 30 | Loss: 0.2758 | Test Acc: 0.5852\n",
            "[DGI+Classifier] Epoch 40 | Loss: 0.2596 | Test Acc: 0.6278\n",
            "[DGI+Classifier] Epoch 50 | Loss: 0.2494 | Test Acc: 0.6611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function of the Code\n",
        "\n",
        "1. **Prepare predictions for GraphSAGE (Model 1)**\n",
        "   - Sets `model1` to evaluation mode.\n",
        "   - Performs forward pass to get logits (`out1`) and predicted labels (`pred1`).\n",
        "   - Retrieves true labels (`true1`) and applies the test mask (`data.test_mask`) to select test samples.\n",
        "\n",
        "2. **Prepare predictions for DGI + Classifier (Model 2)**\n",
        "   - Sets `clf` to evaluation mode.\n",
        "   - Performs forward pass on precomputed embeddings `z` to get logits (`out2`) and predicted labels (`pred2`).\n",
        "   - Retrieves true labels (`true2`) and applies the same test mask.\n",
        "\n",
        "3. **Move tensors to CPU for sklearn**\n",
        "   - Converts masked true and predicted labels for both models to CPU tensors so they can be used by `classification_report`.\n",
        "\n",
        "4. **Print evaluation metrics**\n",
        "   - For **GraphSAGE trained directly**.\n",
        "   - For **DGI + GraphSAGE Classifier**.\n",
        "   - Uses `classification_report()` to display Precision, Recall, F1-score, and Support for each class with 4 decimal precision.\n"
      ],
      "metadata": {
        "id": "c2tHVGtVOBQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Model 1: GraphSAGE\n",
        "model1.eval()\n",
        "out1 = model1(data.x, data.edge_index)\n",
        "pred1 = out1.argmax(dim=1)\n",
        "true1 = data.y\n",
        "mask = data.test_mask\n",
        "\n",
        "# Model 2: DGI + Classifier\n",
        "clf.eval()\n",
        "out2 = clf(z)\n",
        "pred2 = out2.argmax(dim=1)\n",
        "true2 = data.y\n",
        "\n",
        "# Move only the final tensors used in sklearn to CPU\n",
        "true1_cpu = true1[mask].cpu()\n",
        "pred1_cpu = pred1[mask].cpu()\n",
        "\n",
        "true2_cpu = true2[mask].cpu()\n",
        "pred2_cpu = pred2[mask].cpu()\n",
        "\n",
        "# Print evaluation metrics for comparison\n",
        "print(\"====== GraphSAGE Trained Directly ======\")\n",
        "print(classification_report(true1_cpu, pred1_cpu, digits=4))\n",
        "\n",
        "print(\"====== DGI + GraphSAGE Classifier ======\")\n",
        "print(classification_report(true2_cpu, pred2_cpu, digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQCTVUfpva6D",
        "outputId": "b1964546-bf51-436b-ec7d-5c3dcd33b700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====== GraphSAGE Trained Directly ======\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9659    0.9768    0.9713     15587\n",
            "           1     0.6013    0.5042    0.5485      1083\n",
            "\n",
            "    accuracy                         0.9461     16670\n",
            "   macro avg     0.7836    0.7405    0.7599     16670\n",
            "weighted avg     0.9422    0.9461    0.9439     16670\n",
            "\n",
            "====== DGI + GraphSAGE Classifier ======\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9743    0.6577    0.7853     15587\n",
            "           1     0.1322    0.7507    0.2248      1083\n",
            "\n",
            "    accuracy                         0.6637     16670\n",
            "   macro avg     0.5533    0.7042    0.5051     16670\n",
            "weighted avg     0.9196    0.6637    0.7489     16670\n",
            "\n"
          ]
        }
      ]
    }
  ]
}