{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hxIDJYP3AqN",
        "outputId": "eff89357-c4e8-4306-ccb7-dec371c94087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/elli\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/MyDrive/elli\"\n",
        "os.chdir(path)\n",
        "\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install torch-geometric -q\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch_geometric.datasets import EllipticBitcoinDataset\n",
        "from torch_geometric.nn import SAGEConv, DeepGraphInfomax\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "dataset = EllipticBitcoinDataset(root='./elliptic')\n",
        "data = dataset[0].to(device)\n"
      ],
      "metadata": {
        "id": "bktlhkuPtbqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eef77f98-0a68-416a-8a44-fef7af18d0a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://data.pyg.org/datasets/elliptic/elliptic_txs_features.csv.zip\n",
            "Downloading https://data.pyg.org/datasets/elliptic/elliptic_txs_edgelist.csv.zip\n",
            "Downloading https://data.pyg.org/datasets/elliptic/elliptic_txs_classes.csv.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data object structure:\", data)\n",
        "print(f\"Number of nodes: {data.num_nodes}, Number of edges: {data.num_edges}, Feature dimension: {data.num_node_features}\")\n",
        "\n",
        "unique, counts = torch.unique(data.y, return_counts=True)\n",
        "print(\"Label distribution:\")\n",
        "for label, count in zip(unique.tolist(), counts.tolist()):\n",
        "    print(f\"  Label {label}: {count} nodes\")\n",
        "\n",
        "print(f\"Number of training nodes: {data.train_mask.sum().item()}, Number of testing nodes: {data.test_mask.sum().item()}\")\n"
      ],
      "metadata": {
        "id": "VKPPjQAIw0_i",
        "outputId": "2f3d1e7a-4fb0-4dfa-c1a3-acba91b402b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data object structure: Data(x=[203769, 165], edge_index=[2, 234355], y=[203769], train_mask=[203769], test_mask=[203769])\n",
            "Number of nodes: 203769, Number of edges: 234355, Feature dimension: 165\n",
            "Label distribution:\n",
            "  Label 0: 42019 nodes\n",
            "  Label 1: 4545 nodes\n",
            "  Label 2: 157205 nodes\n",
            "Number of training nodes: 29894, Number of testing nodes: 16670\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define GraphSAGE model\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        return self.conv2(x, edge_index)\n",
        "\n",
        "model1 = GraphSAGE(data.num_features, 64, 2).to(device)\n",
        "opt1 = torch.optim.Adam(model1.parameters(), lr=0.01)\n",
        "\n",
        "# Training function\n",
        "def train(model, optimizer):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# Evaluation function\n",
        "@torch.no_grad()\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    pred = out.argmax(dim=1)\n",
        "    acc = accuracy_score(data.y[data.test_mask].cpu(), pred[data.test_mask].cpu())\n",
        "    return acc\n",
        "\n",
        "# Train GraphSAGE\n",
        "for epoch in range(1, 51):\n",
        "    loss = train(model1, opt1)\n",
        "    if epoch % 10 == 0:\n",
        "        acc1 = evaluate(model1)\n",
        "        print(f'[GraphSAGE] Epoch {epoch} | Loss: {loss:.4f} | Test Acc: {acc1:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMmzZCxdvS1B",
        "outputId": "e861b3aa-e7eb-42a6-f106-022a1036f4c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE] Epoch 10 | Loss: 0.1742 | Test Acc: 0.9196\n",
            "[GraphSAGE] Epoch 20 | Loss: 0.1184 | Test Acc: 0.9259\n",
            "[GraphSAGE] Epoch 30 | Loss: 0.0942 | Test Acc: 0.9314\n",
            "[GraphSAGE] Epoch 40 | Loss: 0.0785 | Test Acc: 0.9365\n",
            "[GraphSAGE] Epoch 50 | Loss: 0.0669 | Test Acc: 0.9376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define GraphSAGE model\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        return self.conv2(x, edge_index)\n",
        "\n",
        "model1 = GraphSAGE(data.num_features, 64, 2).to(device)\n",
        "opt1 = torch.optim.Adam(model1.parameters(), lr=0.01)\n",
        "\n",
        "# Training function\n",
        "def train(model, optimizer):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# Evaluation function\n",
        "@torch.no_grad()\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    pred = out.argmax(dim=1)\n",
        "    acc = accuracy_score(data.y[data.test_mask].cpu(), pred[data.test_mask].cpu())\n",
        "    return acc\n",
        "\n",
        "# Train GraphSAGE\n",
        "for epoch in range(1, 51):\n",
        "    loss = train(model1, opt1)\n",
        "    if epoch % 10 == 0:\n",
        "        acc1 = evaluate(model1)\n",
        "        print(f'[GraphSAGE] Epoch {epoch} | Loss: {loss:.4f} | Test Acc: {acc1:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rPXnDNjvXDq",
        "outputId": "9e8a6a9d-5159-4c8c-e295-1ca78061d65e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE] Epoch 10 | Loss: 0.1789 | Test Acc: 0.9379\n",
            "[GraphSAGE] Epoch 20 | Loss: 0.1239 | Test Acc: 0.9304\n",
            "[GraphSAGE] Epoch 30 | Loss: 0.0958 | Test Acc: 0.9374\n",
            "[GraphSAGE] Epoch 40 | Loss: 0.0790 | Test Acc: 0.9418\n",
            "[GraphSAGE] Epoch 50 | Loss: 0.0669 | Test Acc: 0.9461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define DGI encoder (SAGE)\n",
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.conv = SAGEConv(in_channels, hidden_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        return self.conv(x, edge_index)\n",
        "\n",
        "    def summary(self, z, *args, **kwargs):\n",
        "        return torch.sigmoid(z.mean(dim=0))\n",
        "\n",
        "encoder = Encoder(data.num_features, 64).to(device)\n",
        "dgi = DeepGraphInfomax(\n",
        "    hidden_channels=64,\n",
        "    encoder=encoder,\n",
        "    summary=encoder.summary,\n",
        "    corruption=lambda x, edge_index: (x[torch.randperm(x.size(0))], edge_index),\n",
        ").to(device)\n",
        "\n",
        "opt2 = torch.optim.Adam(dgi.parameters(), lr=0.001)\n",
        "\n",
        "# Train DGI\n",
        "for epoch in range(1, 101):\n",
        "    dgi.train()\n",
        "    opt2.zero_grad()\n",
        "    pos_z, neg_z, summary = dgi(data.x, data.edge_index)\n",
        "    loss = dgi.loss(pos_z, neg_z, summary)\n",
        "    loss.backward()\n",
        "    opt2.step()\n",
        "    if epoch % 20 == 0:\n",
        "        print(f'[DGI] Epoch {epoch} | Loss: {loss.item():.4f}')\n",
        "\n",
        "# Use the trained encoder to get z\n",
        "with torch.no_grad():\n",
        "    z = encoder(data.x, data.edge_index).detach()\n",
        "\n",
        "# Define a simple classifier using z\n",
        "class Classifier(torch.nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.lin = torch.nn.Linear(in_dim, out_dim)\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.lin(z)\n",
        "\n",
        "clf = Classifier(64, 2).to(device)\n",
        "opt3 = torch.optim.Adam(clf.parameters(), lr=0.01)\n",
        "\n",
        "# Train classifier\n",
        "for epoch in range(1, 51):\n",
        "    clf.train()\n",
        "    opt3.zero_grad()\n",
        "    out = clf(z)\n",
        "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    opt3.step()\n",
        "    if epoch % 10 == 0:\n",
        "        clf.eval()\n",
        "        pred = out.argmax(dim=1)\n",
        "        acc2 = accuracy_score(data.y[data.test_mask].cpu(), pred[data.test_mask].cpu())\n",
        "        print(f'[DGI+Classifier] Epoch {epoch} | Loss: {loss.item():.4f} | Test Acc: {acc2:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqz110OGvZQI",
        "outputId": "9e6e1335-fad3-42bd-9460-7142921edfac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DGI] Epoch 20 | Loss: 1.3332\n",
            "[DGI] Epoch 40 | Loss: 1.3168\n",
            "[DGI] Epoch 60 | Loss: 1.3127\n",
            "[DGI] Epoch 80 | Loss: 1.3079\n",
            "[DGI] Epoch 100 | Loss: 1.3077\n",
            "[DGI+Classifier] Epoch 10 | Loss: 0.3885 | Test Acc: 0.4195\n",
            "[DGI+Classifier] Epoch 20 | Loss: 0.3062 | Test Acc: 0.5254\n",
            "[DGI+Classifier] Epoch 30 | Loss: 0.2758 | Test Acc: 0.5852\n",
            "[DGI+Classifier] Epoch 40 | Loss: 0.2596 | Test Acc: 0.6278\n",
            "[DGI+Classifier] Epoch 50 | Loss: 0.2494 | Test Acc: 0.6611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Model 1: GraphSAGE\n",
        "model1.eval()\n",
        "out1 = model1(data.x, data.edge_index)\n",
        "pred1 = out1.argmax(dim=1)\n",
        "true1 = data.y\n",
        "mask = data.test_mask\n",
        "\n",
        "# Model 2: DGI + Classifier\n",
        "clf.eval()\n",
        "out2 = clf(z)\n",
        "pred2 = out2.argmax(dim=1)\n",
        "true2 = data.y\n",
        "\n",
        "# Move only the final tensors used in sklearn to CPU\n",
        "true1_cpu = true1[mask].cpu()\n",
        "pred1_cpu = pred1[mask].cpu()\n",
        "\n",
        "true2_cpu = true2[mask].cpu()\n",
        "pred2_cpu = pred2[mask].cpu()\n",
        "\n",
        "# Print evaluation metrics for comparison\n",
        "print(\"====== GraphSAGE Trained Directly ======\")\n",
        "print(classification_report(true1_cpu, pred1_cpu, digits=4))\n",
        "\n",
        "print(\"====== DGI + GraphSAGE Classifier ======\")\n",
        "print(classification_report(true2_cpu, pred2_cpu, digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQCTVUfpva6D",
        "outputId": "b1964546-bf51-436b-ec7d-5c3dcd33b700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====== GraphSAGE Trained Directly ======\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9659    0.9768    0.9713     15587\n",
            "           1     0.6013    0.5042    0.5485      1083\n",
            "\n",
            "    accuracy                         0.9461     16670\n",
            "   macro avg     0.7836    0.7405    0.7599     16670\n",
            "weighted avg     0.9422    0.9461    0.9439     16670\n",
            "\n",
            "====== DGI + GraphSAGE Classifier ======\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9743    0.6577    0.7853     15587\n",
            "           1     0.1322    0.7507    0.2248      1083\n",
            "\n",
            "    accuracy                         0.6637     16670\n",
            "   macro avg     0.5533    0.7042    0.5051     16670\n",
            "weighted avg     0.9196    0.6637    0.7489     16670\n",
            "\n"
          ]
        }
      ]
    }
  ]
}